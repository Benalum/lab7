{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy1Z5AiuiY6-",
        "outputId": "5676f473-013a-4050-fc7b-f2359845c54b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.8.30)\n",
            "Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.18.0\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch torchtext transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov_ch2usmTCt",
        "outputId": "cc0a9594-2783-4b99-9edf-0e6691e88578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-12-01 20:25:01--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  3.55MB/s    in 33s     \n",
            "\n",
            "2024-12-01 20:25:35 (2.40 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load IMDb dataset\n",
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xzf aclImdb_v1.tar.gz\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzlgWTjjdAL_"
      },
      "source": [
        "# Part 1: Fine tuning a pre-trained BERT\n",
        "\n",
        "This code is fine-tuning a pre-trained BERT model on the IMDb dataset for sentiment analysis. It starts with a BERT model that is already pre-trained on a large text corpus (from bert-base-uncased), which has learned general language representations. The code loads this pre-trained model and then trains it further on the IMDb dataset specifically for sentiment analysis (a binary classification task). This process adjusts the weights of the model to better predict positive or negative sentiment based on the IMDb data.\n",
        "\n",
        "Training BERT from scratch would mean initializing a BERT model with random weights and training it on a very large corpus (like Wikipedia or BooksCorpus) to learn language representations, which is computationally intensive. Fine-tuning, on the other hand, starts from a pre-trained model and requires much less data and computation. So, this code fine-tunes the model rather than training from scratch. All layers of BERT are trainable during fine-tuning, it doesn’t freeze the pre-trained layers. This means that the weights of the entire BERT model (not just the final classification layer) are updated during training on the IMDb dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zS81lBcmpEh",
        "outputId": "0d68f74a-cc08-48db-ec22-0c923df8bbb2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/3 Loss: 0.3474839925765991\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/3 Loss: 0.7089992165565491\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/3 Loss: 0.835295557975769\n",
            "Accuracy: 0.9160\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Tokenizer and pre-trained BERT model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puPOIPr9WIjn"
      },
      "source": [
        "# Part 2: Gradual unfreezing\n",
        "\n",
        "\n",
        "Gradual unfreezing is a training strategy used in transfer learning. The idea is to fine-tune a pretrained model by initially freezing most of its layers, training the top (or newly added) layers, and progressively unfreezing more layers as training progresses. This allows the model to first learn the new task in a stable manner before updating the weights of the earlier, more general layers.\n",
        "\n",
        "When you load a pretrained model (like BERT), it has many layers, often with millions of parameters. These pretrained weights are optimized for a general task (e.g., language modeling in BERT). Initially, you freeze all layers except for the task-specific classifier (e.g., the final linear layer) by setting requires_grad=False for those layers. This ensures only the classifier is updated during the initial training phase.\n",
        "\n",
        "\n",
        "As training progresses, you progressively unfreeze earlier layers in the model, allowing their weights to be fine-tuned. This gradual unfreezing avoids destabilizing the model by ensuring that earlier, more general layers are only updated after the task-specific layers have been refined.\n",
        "\n",
        "* Each epoch (or after a certain number of epochs), you unfreeze one or more layers.\n",
        "* This can be done sequentially, layer by layer, or in groups (e.g., unfreezing an entire block of layers).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkxy5zTgBKNn",
        "outputId": "9370d144-f504-43f8-f170-e9f7f5ef9351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/3 Loss: 0.033939775079488754\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/3 Loss: 0.21184031665325165\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/3 Loss: 0.0058774822391569614\n",
            "Accuracy: 0.9172\n"
          ]
        }
      ],
      "source": [
        "# Gradual unfreezing for sentiment analysis and question answering with BERT on IMDb\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Freeze all layers initially\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# keep the classifier layer trainable\n",
        "for name, param in model.named_parameters():\n",
        "    if \"classifier\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "\n",
        "# Unfreeze layers gradually\n",
        "def unfreeze_layers(model, epoch):\n",
        "    # Gradually unfreeze one encoder layer per epoch, starting from the last layer\n",
        "    if epoch < len(model.bert.encoder.layer):\n",
        "        for param in model.bert.encoder.layer[-(epoch + 1)].parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        unfreeze_layers(model, epoch)  # Gradual unfreezing\n",
        "\n",
        "        # Debugging trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        # Define optimizer with trainable parameters\n",
        "        optimizer = AdamW(trainable_params, lr=2e-5)\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize the BERT tokenizer and model for sentiment analysis\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqX2NWDhZwPE"
      },
      "source": [
        "# Part 3: Question answering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udV3bG_TfkE6",
        "outputId": "e954ed27-7a73-4329-c777-c66f0105c1f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review 1:\n",
            "Text: By 1971 it was becoming more and more obvious that Hammer film studios were on the way out . HANDS OF THE RIPPER is a case in point where even the idea smacks of desperation - The spirit of Jack The Ripper posses his own daughter ! Yeah okay no one was expecting a documentary but this plot seems to ...\n",
            "Predicted Sentiment: positive\n",
            "Actual Sentiment: negative\n",
            "Reason: \n",
            "\n",
            "\n",
            "Review 2:\n",
            "Text: I'm one of those gluttons for punishment when it comes to sitcoms these days-I still will check them out every once in a while.My observation is that most of them aren't very funny even the ones on major networks that are getting high ratings ,I just don't get who is finding them gut busting funny. ...\n",
            "Predicted Sentiment: positive\n",
            "Actual Sentiment: negative\n",
            "Reason: [CLS] why is this review positive ? [SEP]\n",
            "\n",
            "\n",
            "Review 3:\n",
            "Text: Ernesto is a man that makes a living out of duping other solid citizens of their hard earned money. Together with Manco, an older man with a lot of experience, he pulls out capers that allow him to make a decent living, but that is not making him a rich man by any means. Enter Federico, an older man...\n",
            "Predicted Sentiment: positive\n",
            "Actual Sentiment: positive\n",
            "Reason: [CLS] why is this review positive ? [SEP] ernesto is a man that makes a living out of duping other solid citizens of their hard earned money . together with manco , an older man with a lot of experience , he pulls out capers that allow him to make a decent living , but that is not making him a rich man by any means . enter federico , an older man who is more experience in the art of deception . together with the younger ernesto they prove a winning combination . that only lasts until pilar , federico ' s former love interest , appears in the picture . < br / > < br / > this spanish film directed by miguel bardem , is light in tone and pleasant to sit through\n",
            "\n",
            "\n",
            "Review 4:\n",
            "Text: This is a wonderful film taking place during the romantic period of the Civil War. This film is a must see for Eastwood Fans and Eastwood claims this is one of his most favorite films that he did. I couldn't agree more. Watch out! This is a spoiler- Eastwood does die in the end. Eastwood and directo...\n",
            "Predicted Sentiment: positive\n",
            "Actual Sentiment: positive\n",
            "Reason: \n",
            "\n",
            "\n",
            "Review 5:\n",
            "Text: This film is the best kung fu film of all time. Although there is not wire-work and special effects like those used in Crouching Tiger, this movie uses ingenuity and creative camera-work to create memorable fighting moments, and the fight scenes are well choreographed and tight. There is a ton of ac...\n",
            "Predicted Sentiment: positive\n",
            "Actual Sentiment: positive\n",
            "Reason: this film is the best kung fu film of all time\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "import os\n",
        "import tarfile\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load tokenizer and models\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "sentiment_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).to(device)\n",
        "qa_model = BertForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\").to(device)\n",
        "\n",
        "# Prepare data: extract 5 random reviews and labels\n",
        "def load_reviews(path, label):\n",
        "    reviews = []\n",
        "    for filename in os.listdir(path):\n",
        "        with open(os.path.join(path, filename), \"r\", encoding=\"utf-8\") as f:\n",
        "            reviews.append((f.read(), label))\n",
        "    return reviews\n",
        "\n",
        "# Function to ask questions about sentiment\n",
        "def ask_bert_review(text, question):\n",
        "    inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
        "    answer_start_scores, answer_end_scores = qa_model(**inputs, return_dict=False)\n",
        "\n",
        "    answer_start = torch.argmax(answer_start_scores)\n",
        "    answer_end = torch.argmax(answer_end_scores) + 1\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
        "    return answer\n",
        "\n",
        "\n",
        "# Load positive and negative reviews\n",
        "positive_reviews = load_reviews(\"aclImdb/test/pos\", label=1)\n",
        "negative_reviews = load_reviews(\"aclImdb/test/neg\", label=0)\n",
        "\n",
        "\n",
        "# Combine and sample reviews\n",
        "all_reviews = positive_reviews + negative_reviews\n",
        "random.shuffle(all_reviews)\n",
        "sample_reviews = random.sample(all_reviews, 5)\n",
        "\n",
        "# Analyze reviews\n",
        "results = []\n",
        "\n",
        "for review, label in sample_reviews:\n",
        "    # Sentiment classification using pretrained bert - not fine tuned\n",
        "    inputs = tokenizer(review, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
        "    sentiment_output = sentiment_model(**inputs)\n",
        "    sentiment = torch.argmax(sentiment_output.logits, dim=1).item()\n",
        "    sentiment_label = \"positive\" if sentiment == 1 else \"negative\"\n",
        "    actual_label = \"positive\" if label == 1 else \"negative\"\n",
        "\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        \"review\": review,\n",
        "        \"predicted_sentiment\": sentiment_label,\n",
        "        \"actual_sentiment\": actual_label,\n",
        "        \"reason\": ask_bert_review(review, f\"Why is this review {sentiment_label}?\")\n",
        "    })\n",
        "\n",
        "# Print results\n",
        "for i, result in enumerate(results):\n",
        "    print(f\"Review {i + 1}:\")\n",
        "    print(f\"Text: {result['review'][:300]}...\")  # Truncate for display\n",
        "    print(f\"Predicted Sentiment: {result['predicted_sentiment']}\")\n",
        "    print(f\"Actual Sentiment: {result['actual_sentiment']}\")\n",
        "    print(f\"Reason: {result['reason']}\")\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sfIbU7ZA3Kc"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQR49-ZYmrXQ"
      },
      "source": [
        "# TO-DO\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Parts 1 and 2\n",
        "\n",
        "\n",
        "* **Experiment with Different Pretrained Models**:\n",
        "   - Try other transformer-based models like `distilbert-base-uncased` or `roberta-base`. Compare their performance with `bert-base-uncased`.\n",
        "\n",
        "   roberta-base is by far the worst model to use under these circumstances.  distillbert-based-uncased is by far much quicker.  Bert-based-uncased is the best for accuracy but takes a little bit longer.\n",
        "\n",
        "* **Adjust Hyperparameters**:\n",
        "   - Experiment with learning rates (e.g., `1e-5`, `5e-5`, `2e-6`) and batch sizes to observe their impact on model performance.\n",
        "   - Evaluate how changing the number of epochs affects validation accuracy and loss.\n",
        "\n",
        "  for distillbert-based-uncased it seems that lower epoch, lower batch sizes seem to help the most.  For bert-based-uncased it seems to  be have a lot of fluctuation to determine what helps and what doesnt but it seems that the higher the epoch the better.  for the robertya base it seems that the higher number of epochs helps and a lower learning rate number helps.\n",
        "\n",
        "* **Comparative Analysis**:\n",
        "   - Compare the performance of fine-tuning with gradual unfreezing to fine-tuning with all layers unfrozen from the start.\n",
        "   - Discuss the computational trade-offs (time vs. accuracy) and performance differences.\n",
        "  Time vs accruacy is pretty comparable, they both came in around 22 minutes and they both are around a .92 accuracy with bert-based-uncased taking the win with a .9201.  Although with having to test all the different bert-based-uncased sets, it was quite timeconsuming but if you just take that one in particular they are comparable.\n",
        "\n",
        "---\n",
        "\n",
        "## Part 3\n",
        "\n",
        "* **Manual Review**:\n",
        "   - Manually analyze a few QA outputs to assess whether the model’s reasoning aligns with human judgment. Highlight discrepancies and discuss their causes.\n",
        "\n",
        "\n",
        "  The model predicts positive when in reality is it negative, possibly from the sarcasm that makes it hard to determine what is going on.\n",
        "\n",
        "* **Fine-tuned BERT**:\n",
        "   - Replace the simple pretrained BERT with your best fine-tuned model and/or replace BERT with other transformer-based model for Q&A\n",
        "\n",
        "   Done\n",
        "\n",
        "* **Prompt Engineering**:\n",
        "   - Experiment with different phrasing for the question (e.g., \"What makes this review positive/negative?\" or \"Explain the sentiment of this review.\"). Discuss how the phrasing affects the model's answers.\n",
        "\n",
        "\n",
        "   this one was correct with negative to negative, which the last one only predicted positive.  Different ways of stating things can have a positive of negative impact on how it is represented.\n",
        "\n",
        "* **Entity-Specific Analysis**:\n",
        "   - Modify the question to focus on specific entities or aspects in the review (e.g., \"What does the review say about the acting?\" or \"Why is the plot criticized?\"). Discuss the model’s ability to handle nuanced questions.\n",
        "\n",
        "  The model failes due to lack of structure or input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyCQBGmXLFCe",
        "outputId": "d4982dfc-67da-43b6-8460-c660f5767eca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 104\n",
            "Epoch 1/3 Loss: 0.16393446922302246\n",
            "Number of trainable parameters: 104\n",
            "Epoch 2/3 Loss: 0.557553768157959\n",
            "Number of trainable parameters: 104\n",
            "Epoch 3/3 Loss: 0.08951559662818909\n",
            "Accuracy: 0.9144\n",
            "Total time taken: 00:12:21 using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "import time  # Import the time module\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} using the A100 GPU\")\n",
        "\n",
        "# distilbert-base-uncased, BATCH_SIZE = 8,lr=1e-5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkABoTHkT6tR",
        "outputId": "d23ba312-1fd7-408a-f52f-6cf2a35bd6ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 104\n",
            "Epoch 1/3 Loss: 0.14459463953971863\n",
            "Number of trainable parameters: 104\n",
            "Epoch 2/3 Loss: 0.03000408038496971\n",
            "Number of trainable parameters: 104\n",
            "Epoch 3/3 Loss: 0.01974307745695114\n",
            "Accuracy: 0.9078\n",
            "Total time taken: 00:12:16 using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "import time  # Import the time module\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} using the A100 GPU\")\n",
        "\n",
        "# distilbert-base-uncased, BATCH_SIZE = 8,lr=2e-5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620,
          "referenced_widgets": [
            "b2ea17d53d8b46008be70d30b946aeac",
            "2928393860d749158806f18ad51edcf1",
            "06751ea2f8104a2598d05d75cd115a27",
            "e430da78a58f4f508102f5325da491e5",
            "9458745579664e14bd9e490282fd2e83",
            "603b6aba7350444788f6ac99afbf3e55",
            "424195d8112246abb63def8952af26d4",
            "0497a6ba5d5348a98e957731986d0a4c",
            "71b9ea5ba4f048118d6e7025d8334216",
            "d3954bcd89bf4787981989057167bd4c",
            "49d48d157fd146d1b06a77cd536ffb7b",
            "9a3fe022f650482a8255191670896c24",
            "3855186ba12540a48adaeff8709813bb",
            "f8c2cf0e4559464e9cc1691c47efdf58",
            "cc31c93623214d328cc8dea993ae673f",
            "c7660a3ca2b24623b11d94b0a0d830b3",
            "10a1bc9dccee4488b607555bb4c0d29b",
            "455ff4ba688c45bcbec5aec28721e8b8",
            "2b7e461650bb449d9a1001390f8f07a3",
            "b4e02ae1d8f346e1835737a33431238d",
            "18d9005782ea4ce680d732d53b9d0a16",
            "c588915afe6841a6ab8a2950e5856a3c",
            "5912df4c9941493899a1fd2349561428",
            "ab1c400f54f74f468f8444b9ee2cc7fb",
            "1ebc3387b20e467cae158205e9d90074",
            "9893c9670af64ca795597b513e657d77",
            "9efac6017eb04cc9a775968ea56d298c",
            "eb55bbb85de74b3db8d1ff85bac0effa",
            "2db1dc1ccfa5430f9c5ecf902cf988f1",
            "9af9c4bca7124010b42413ac70a3c0da",
            "594cea9f10c943b4ade89940645686f2",
            "0c9f4274ddea481c9c1d0e80e246be6d",
            "4f5c7bdb9e814cabac72cc321c59dfb3",
            "ff6dfcbb37aa4d689a96692758f28e47",
            "977f8b62e34c4404814628d5732d82e3",
            "a5121dd2cf514d228a932e69f00d6305",
            "94e62f1110044ff69120667394b98918",
            "4171b12cebaa4feb81de1a5f229d6811",
            "a5e704ea75514f6f8df0ae1ad849a296",
            "5b99df92219d47e1b95994c24bc8ee26",
            "26e6413e1faf438692f11281640cfbd5",
            "e4dd15ad30b1480ba597ea08bf030a17",
            "ccfe9d8f48d7483dbda121816b92a0e5",
            "5d8b5921d17d4ab9bbc6623048f91047",
            "8f4b065b292244ce8b66b0a9e7c2b001",
            "59d1cf1733cb44b09d8ecf798176a73f",
            "a2323cf43ef94d47bb027485baecaa32",
            "fab5f6807f77487fbea80331e753fd3d",
            "f9727fce24284fe3af0e71164e95470a",
            "93ca550fe8b3482aaeba280c9aeccd7c",
            "1ead1fed8002451d991ffc73da4b827d",
            "b4d400fb128c48df88ea54f828470dbe",
            "ef86d9222dbb434ab515853dc9047b39",
            "05e93cc40acb4b409d3427d424d67734",
            "9ea94019b2bc4aef8515562715fb20ec",
            "7c37ecfeae874e3f84130ed2984346ec",
            "5dd5b8a67b3e406a9355d542c7370001",
            "a895076f177144c4b4bf0cbdc6400a31",
            "a952203b044f4c1ba2278b2b6a69c913",
            "bd8b94cbfad841c1bdf9de2bc745f8a1",
            "7adcf7f5c8e0482ba6f2d7288da4b464",
            "a69bd0017f8b4ee5b0a3cd02bea10af6",
            "37086f365d154bba8e598837b3357667",
            "1c17d76c7ee74866a7de6aa9f2249943",
            "af4ab7aaf9914da9a7370397d19dd2b9",
            "0372eb2262d84d48932902dc96117130"
          ]
        },
        "id": "5A0NgJc6fx1-",
        "outputId": "8209f634-32ef-474f-b972-fdc7d70f5fc2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2ea17d53d8b46008be70d30b946aeac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a3fe022f650482a8255191670896c24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5912df4c9941493899a1fd2349561428",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff6dfcbb37aa4d689a96692758f28e47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f4b065b292244ce8b66b0a9e7c2b001",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c37ecfeae874e3f84130ed2984346ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 201\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c2be2fdb24c2>\u001b[0m in \u001b[0;36m<cell line: 137>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;31m# Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-c2be2fdb24c2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, scheduler, epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_by_lr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWPyNOCqdeZh"
      },
      "outputs": [],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import time  # Import the time module\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using A100 GPU\")\n",
        "\n",
        "# distilbert-base-uncased, BATCH_SIZE = 8,lr=5e-5,EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509,
          "referenced_widgets": [
            "dee1440d192844aba962d7cf9ba34daf",
            "a4b253d546014778bec6e1a18fb1397e",
            "35fa984d493e41208bbad1e9990b8c88",
            "e80c4b0f681e4ca3b28ce5d24432c2d6",
            "74a8e47be0a44f2696d73a4807bdce93",
            "368333b4358643fda608795972f81c11",
            "341db97d2fa245789d0f648aba7df34c",
            "302f83452c6243fdba3172e1d9cb37bb",
            "fdd0877738dc43239a1a8e324922ddce",
            "39bb9782d55f45aebd4dee7c39dad393",
            "5ea591de78d04d29933686656c2622f5",
            "0f523682c1674262a72446aa140169ee",
            "90042747e7ee4f84bd68a22c03daebb0",
            "434b9f12652e40fd832ac6ef0e69999f",
            "9b4de354f1b149c4bb75aa3e5b84e6f3",
            "d787177972b5461d961545b729c1f573",
            "ed9c97fa11de4637b3153d9615829426",
            "195657076576462699a9822103ab2923",
            "39c07da9f37c4a5fbd5ba842280d81b3",
            "1feb4598a0804213b0d1694bf136721f",
            "37bb3dac665d4e0fa00fad794e1e5d57",
            "177c5ae36cd04a27b227669d3189b7e2",
            "31408df57ce445d6bb580d6853c004db",
            "fe6bed3e941442f69dddbdb3d113a17b",
            "5535ad1c96b4477486af5916c7baa04f",
            "276e2891f8c4421587d458b839632240",
            "21c6e4408c5b4558ab995753b02cfc04",
            "eef1581667d24e0387e1e04ab82c170c",
            "a1c3f75821c245b9a2e702c0875e0622",
            "1dc9f59abca04daf9a7ca81bf9f890e7",
            "97a4e003eb494efca981a487c02383ec",
            "82c0c3ebc7894f4b8e9a1dae64c81e35",
            "85ee92884b2645ea977ce023636975c8",
            "ee5ce0cfa81341129a5cec5bcfccdafd",
            "d5b7f1d416b843969be06e3e94a0b9fa",
            "a5c1c95209f64443b42192a581d84341",
            "7f9668b543734a8ab3b1b84dc3372c86",
            "67d7ee62dd864e0a9c69fdf486822176",
            "8da059125c7944b99431b1c60cae8c8e",
            "b9e29a225d764d6490e89441389ea7f3",
            "c2d1b4dd96d445548deaed3c14166613",
            "283a5148712b456eb59342a4907dec5a",
            "c9642d14def744bf85a49e233188de9d",
            "2b58f91db9314ce390a564cba355b3ab",
            "4156ec1a70ab4459ac70fd8004e15a2e",
            "d3126ebacfc94b0f92ba0e683cd441ff",
            "3e6dd9db67834c90b2a1b8c98702023b",
            "e8ca4449e1634e09b33c111ce4e21f2b",
            "7e533bfc87fa437ab36a3a7eede098e1",
            "a38b1fddce15453ba505a929343e9f6e",
            "51f74a70012c42a684ba3deb8b9a5c22",
            "4ac314c185bf4bc3b933deba5756c89d",
            "902dd0a09b6c48f08e635d34e64592ca",
            "87dae17fe02040768a113f49da8df7d8",
            "763daa0709a74d8f8cfd68d10e3d31a5"
          ]
        },
        "id": "Gd5rnw-r1YXn",
        "outputId": "ffec0a6b-ae6c-4771-e0c9-26b7865cf071"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dee1440d192844aba962d7cf9ba34daf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f523682c1674262a72446aa140169ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31408df57ce445d6bb580d6853c004db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee5ce0cfa81341129a5cec5bcfccdafd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4156ec1a70ab4459ac70fd8004e15a2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 104\n",
            "Epoch 1/3 Loss: 0.4708547592163086\n",
            "Number of trainable parameters: 104\n",
            "Epoch 2/3 Loss: 0.551298975944519\n",
            "Number of trainable parameters: 104\n",
            "Epoch 3/3 Loss: 0.08882863074541092\n",
            "Accuracy: 0.8624\n",
            "Total time taken: 935.42 seconds using the L4 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import time  # Import the time module\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "print(f\"Total time taken: {total_time:.2f} seconds using the L4 GPU\")\n",
        "# distilbert-base-uncased, BATCH_SIZE = 8,lr=5e-5,EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509,
          "referenced_widgets": [
            "f987458617e345df9647d99d2c71accc",
            "c529239732f04195a8407896c3c740be",
            "c4bd5871717a49eea739c18660c62d22",
            "662ba766179d4030870f508a47e90505",
            "122c29612d2b4fc5844f1b394a62bb8a",
            "2870f14d38174edd9484fb4f6e7c80f8",
            "b8073bd4f3464c37aca358fe65095c71",
            "c78cc67e5bc34574807d8dfeb26a1887",
            "bd1038c79ae74e54aaae5d7121069064",
            "76cf09d4f7ab4decade762aa5cb7d11c",
            "f456ad032ee645588e8b418bad955625",
            "7adf3aa1ab2e4b0b9a91f1c976b80f12",
            "4cb27dcad8d742d6939770ad6b87592a",
            "455085ae520a4303b911398c0c84a984",
            "14a991f6073440e28955fc183e5d3ad2",
            "86c1b6111a724c03a6d05d72a7fc4c3d",
            "4dcfb1e6945946e7803f6c85a09b021f",
            "ea3d8cca4d754dac878ae7233fde0e47",
            "724a3b8ea5a04808948e25b48a3d12cc",
            "712ad803c6a345368c679770ea00b26b",
            "8d964bda6c3f4b38ad31229adb201422",
            "bfa54e3f85eb43bdb703bbb7dd051cdc",
            "0f3b2a978efb42008769bb7a132a32ce",
            "3a6da36b5dac463c9426ae79bfc828c6",
            "d38655ab990748c7a5b7859347c2bddc",
            "229d04a4abca420db5fb2ad79b0835e4",
            "022eeb410eb74e0ebdf3cb814e993978",
            "e1a0c928430b4ed68af37ff567a9e7b4",
            "102817fa28d74602a37dbd2868a18677",
            "2d8662277df04b8ca67fbadcd6c74756",
            "6d7cb082184f4b808aa8716a522d400a",
            "a96da3ae855045fcb5ff7c7bfe97a6da",
            "4f25bb0cc2b941bc9471e2a9be780fa2",
            "549b3c03f81747838838537572f03296",
            "94f735bdf75f4af4b1b0cb02102c7d06",
            "cb54f8a6e4f148f5b516b505e26cb03c",
            "59a883804d9e4b388866e44fff30dc52",
            "135bd32ea0b74cba83d78f847375bedb",
            "369aaa670a624d97bf9c37e7999ab03e",
            "56509619de3d479db1363222621f07b8",
            "de38a0aedb054bbd89550bc092b98e82",
            "e415008bce1347e698758b6a1e532a61",
            "f38dd426b89542ff8574519d1545e05b",
            "e0dd1d6af50644e3957b3ad6f0f9ec47",
            "0b50855490f24e5993613bac79632882",
            "e64d4a042b564afa86f12dd24a1d20ad",
            "1f4655233f364c02bd10dadfe16606bc",
            "ffe5682a20c84ea9bc18ce60f8758d2b",
            "ec150a39e814419e81b37df7c24b0939",
            "e722364c5be74d61a1b37e3966fdd888",
            "19932a39f48a4829b0945c0e2ad5294e",
            "6ebf091061bf437099b0c5115f850036",
            "548837eb29d9493cbc8ccfc519ddbdab",
            "754c7f138dfe407cbfa5e69001341630",
            "5e95dfca62104215a7aa775d75bb8827"
          ]
        },
        "id": "Vd88jpaQ5Vfg",
        "outputId": "384466ba-b9d6-4dfb-ef9f-96f03cbc2187"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f987458617e345df9647d99d2c71accc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7adf3aa1ab2e4b0b9a91f1c976b80f12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f3b2a978efb42008769bb7a132a32ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "549b3c03f81747838838537572f03296",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b50855490f24e5993613bac79632882",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 104\n",
            "Epoch 1/3 Loss: 0.32813239097595215\n",
            "Number of trainable parameters: 104\n",
            "Epoch 2/3 Loss: 0.08421207219362259\n",
            "Number of trainable parameters: 104\n",
            "Epoch 3/3 Loss: 0.1542925238609314\n",
            "Accuracy: 0.8543\n",
            "Total time taken: 728.90 seconds using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import time  # Import the time module\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "# distilbert-base-uncased, BATCH_SIZE = 8,lr=5e-5,EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frJWI0XSeizN",
        "outputId": "7ad684a7-3d79-41f0-e0f4-0368ec4ac0a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 104\n",
            "Epoch 1/3 Loss: 0.23734691739082336\n",
            "Number of trainable parameters: 104\n",
            "Epoch 2/3 Loss: 0.06410857290029526\n",
            "Number of trainable parameters: 104\n",
            "Epoch 3/3 Loss: 0.1856422871351242\n",
            "Accuracy: 0.9046\n",
            "Total time taken: 00:12:12 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "# distilbert-base-uncased, BATCH_SIZE = 8,lr=2e-6,EPOCHS = 3\n",
        "\n",
        "import torch\n",
        "import time  # Import the time module\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=2e-6, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L09igTsie4l0",
        "outputId": "cb291517-4fd8-4477-c0ab-3e94404298e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 104\n",
            "Epoch 1/3 Loss: 0.19335265457630157\n",
            "Number of trainable parameters: 104\n",
            "Epoch 2/3 Loss: 0.06016955152153969\n",
            "Number of trainable parameters: 104\n",
            "Epoch 3/3 Loss: 0.008294796571135521\n",
            "Accuracy: 0.9090\n",
            "Total time taken: 00:10:54 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "# distilbert-base-uncased, BATCH_SIZE = 16,lr=2e-5,EPOCHS = 3\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "import time  # Import the time module\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 16\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXIqVe69e-jp",
        "outputId": "4c562528-299f-4a7a-ad12-1824bb901c95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 104\n",
            "Epoch 1/5 Loss: 0.3543960452079773\n",
            "Number of trainable parameters: 104\n",
            "Epoch 2/5 Loss: 0.03235465660691261\n",
            "Number of trainable parameters: 104\n",
            "Epoch 3/5 Loss: 0.031877122819423676\n",
            "Number of trainable parameters: 104\n",
            "Epoch 4/5 Loss: 0.0012970701791346073\n",
            "Number of trainable parameters: 104\n",
            "Epoch 5/5 Loss: 0.00164070597384125\n",
            "Accuracy: 0.9130\n",
            "Total time taken: 00:16:35 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "# distilbert-base-uncased, BATCH_SIZE = 16,lr=2e-5, EPOCHS = 5\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "import time  # Import the time module\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 16\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 5\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ6JKUynFHU2"
      },
      "source": [
        "Bert-Based Uncased below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8I8BFlsO5LZ"
      },
      "outputs": [],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "import time  # Import the time module\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Tokenizer and pre-trained BERT model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "\n",
        "# bert-based-uncased, lr=1e-5, BATCH_SIZE = 8, EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351,
          "referenced_widgets": [
            "cc98115d561345c3a3daba79b69e3f58",
            "4ddac4494b6a4920b8ae7749a96f3035",
            "da83b2b6bf7240c9b49c14de78f073d8",
            "d362376dd5cb48d3a144096b1d46b83e",
            "04ac3db545a74fd0ac0e7c3ad2d03e23",
            "248e2e625f2d4850a4fc6f1eea72c807",
            "e71976cf7b4446299fa647135a71053c",
            "a561b48c27b84d9db34c7a80f555a5ae",
            "ba6a4a95dfe44c6f9f8eb02e5135c239",
            "1694fbe70e424e1e9898299bcc0a844e",
            "c6c62f01e24c448c9e06abbe3349d77a",
            "af7c12de491744f28ee62f84ef771135",
            "5918438a52844d54acca528eed82e655",
            "c4826ba981bd4d77884008e2e9696181",
            "55dd229b4d8c42f784f435c74a8d1573",
            "5a473597c2b54f0aa0bef3b8886ad59d",
            "fce48e586a354b99955e4e3db8eb0582",
            "0cd6c1834ae7443a968534044d028b97",
            "a4591631330e4c759f2ab171e1c2cf5e",
            "332e49692539416fb2a941f8bb122450",
            "cde6a87bb25246a8ae9de6e70423e6f3",
            "ec2ab47f5b7948548f4df152f7ce2e88",
            "b3bc77d461564bd78150ec30c4decef8",
            "e0f7d499e67e4b4284170d6959f46c45",
            "b637ca72106d4518bc551a23e47d2668",
            "984b0a662f374d50a2a9d8541434488f",
            "59ae7c8e68004f7b8b90ee003c3faadb",
            "68399aace30e45a691a8975341d7b538",
            "86a7e400a2e0436e88a6f8d1755ffd72",
            "ec9a28cf00ce47c3854eaf51929353e8",
            "5881c9351d74495894f300831fd3d2c4",
            "c355bcf4866244d1aafea956317145d2",
            "9009678d38f3419b9a5c68f2bf8407d5",
            "40656adca53240e89854d74aa9aa4ce7",
            "03fa436c8ad4470e8eddd3474719d900",
            "5fe97cbc9d7b41b3aed36ce368b62960",
            "3dc6941f051a48fb9aea6ee1eac0f1b6",
            "80d6394cab8b4c5792abd8295b096700",
            "138f5b6d895f4cc3ab880a2ea107d8f5",
            "4507ca816cd042f58af5596f4bbdb351",
            "372af8035532404492216bc07623d9a5",
            "56981526527a4ba8b1db9e7640db5754",
            "1b5a7669a2da4d369e592d00e9540bb1",
            "dee9ddcbdd1f446abb8bb196efe5f7fc",
            "be3fd2681a9743708998a341448564d7",
            "efb8073881424745abcc80fef7f58615",
            "84397eb3e19547de82f2d035378180ca",
            "c1a15e4556614d1ea725c73d6ce461ef",
            "68b2fa37bbdb4b47983ba2d526f1459c",
            "6560ca377cca48b498a38744cbe70ed9",
            "e8616c4662404401b720ff8500ce4f34",
            "c86303f43e26496d9e69e3bca5a1b753",
            "6a47970f9b5847678f1f31c440868ec2",
            "dd49addce36d435da3dceff433aa95f7",
            "c3afd4544b1f4fecb09d99a736b003b1"
          ]
        },
        "id": "ueAHLObnFCur",
        "outputId": "7debb0e7-8de9-49f6-d79b-10ca0cd731ae"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc98115d561345c3a3daba79b69e3f58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af7c12de491744f28ee62f84ef771135",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3bc77d461564bd78150ec30c4decef8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40656adca53240e89854d74aa9aa4ce7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be3fd2681a9743708998a341448564d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/3 Loss: 0.6975260972976685\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/3 Loss: 0.5747290849685669\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/3 Loss: 0.37268394231796265\n",
            "Accuracy: 0.7603\n",
            "Total time taken: 00:22:09 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "import time  # Import the time module\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Tokenizer and pre-trained BERT model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "\n",
        "# bert-based-uncased, lr=2e-5, BATCH_SIZE = 8, EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Eku9oMFgjr",
        "outputId": "4ff5c8bd-e0d2-473a-f1ad-ac0467d402d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/3 Loss: 0.10754819214344025\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/3 Loss: 0.07577671110630035\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/3 Loss: 0.029499314725399017\n",
            "Accuracy: 0.9201\n",
            "Total time taken: 00:22:05 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "import time  # Import the time module\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Tokenizer and pre-trained BERT model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "\n",
        "# bert-based-uncased, lr=1e-5, BATCH_SIZE = 8, EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1z_W3n6FsqC",
        "outputId": "eadbf303-7a4a-4b14-ea11-34017bf650c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/3 Loss: 0.7242938876152039\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/3 Loss: 0.6792218685150146\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/3 Loss: 0.7002463936805725\n",
            "Accuracy: 0.5000\n",
            "Total time taken: 00:22:00 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "import time  # Import the time module\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Tokenizer and pre-trained BERT model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "\n",
        "# bert-based-uncased, lr=5e-5, BATCH_SIZE = 8, EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz5IRo6rFwdv",
        "outputId": "fbbdaf17-1693-4e6c-9699-bdfb8ba71865"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/3 Loss: 0.6127933859825134\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/3 Loss: 0.19958460330963135\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/3 Loss: 0.026974782347679138\n",
            "Accuracy: 0.9165\n",
            "Total time taken: 00:22:04 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "import time  # Import the time module\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Tokenizer and pre-trained BERT model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=2e-6, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "\n",
        "# bert-based-uncased, lr=2e-6, BATCH_SIZE = 8, EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOks06fWF1WE",
        "outputId": "ac2ba19f-f250-4c56-e4bc-988acff862d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/3 Loss: 0.5284695625305176\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/3 Loss: 0.030269289389252663\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/3 Loss: 0.12884077429771423\n",
            "Accuracy: 0.9154\n",
            "Total time taken: 00:20:47 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "import time  # Import the time module\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Tokenizer and pre-trained BERT model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 16\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=2e-6, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "\n",
        "# bert-based-uncased, lr=2e-6, BATCH_SIZE = 16, EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD2vvIP0F6lT",
        "outputId": "376341f8-ce18-4277-96ca-b79491aaafea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/5 Loss: 0.5571572780609131\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/5 Loss: 0.5179071426391602\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/5 Loss: 0.013046866282820702\n",
            "Number of trainable parameters: 201\n",
            "Epoch 4/5 Loss: 0.07614007592201233\n",
            "Number of trainable parameters: 201\n",
            "Epoch 5/5 Loss: 0.025075694546103477\n",
            "Accuracy: 0.9178\n",
            "Total time taken: 00:33:06 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "import time  # Import the time module\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Tokenizer and pre-trained BERT model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 16\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 5\n",
        "optimizer = AdamW(model.parameters(), lr=2e-6, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "\n",
        "# bert-based-uncased, lr=2e-6, BATCH_SIZE = 16, EPOCHS = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYfEcTXPdUu6"
      },
      "source": [
        "roberta-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgfnRM2lGO-5",
        "outputId": "60342e35-8e99-4517-ee41-5c8ade2e27eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/3 Loss: 0.6946337223052979\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/3 Loss: 0.706021249294281\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/3 Loss: 0.7090902328491211\n",
            "Accuracy: 0.5000\n",
            "Total time taken: 00:22:02 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "import time  # Import the time module\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize tokenizer and model for roberta-base\n",
        "okenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "\n",
        "# 'roberta-base, BATCH_SIZE = 8, lr=2e-5, EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lenjkYGLHGCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "695e73a2-23a9-4a11-b57c-bc8512494dd0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/3 Loss: 0.6966667175292969\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/3 Loss: 0.7459478378295898\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/3 Loss: 0.4786936044692993\n",
            "Accuracy: 0.7103\n",
            "Total time taken: 00:22:11 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "import time  # Import the time module\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize tokenizer and model for roberta-base\n",
        "okenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "\n",
        "# 'roberta-base, BATCH_SIZE = 8, lr=1e-5, EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLFdtRMWHLus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fc02ac-1439-4ab7-f145-adcd9b5b208e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/3 Loss: 0.7172223329544067\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/3 Loss: 0.6890016198158264\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/3 Loss: 0.686179518699646\n",
            "Accuracy: 0.5000\n",
            "Total time taken: 00:22:04 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "import time  # Import the time module\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize tokenizer and model for roberta-base\n",
        "okenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "\n",
        "# 'roberta-base, BATCH_SIZE = 8, lr=5e-5, EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKdd5nyLHPIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ac74aa-15de-4576-c4ed-d5d6acfb0086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/3 Loss: 0.3895869255065918\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/3 Loss: 0.5510010123252869\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/3 Loss: 0.39616188406944275\n",
            "Accuracy: 0.7592\n",
            "Total time taken: 00:22:06 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "import time  # Import the time module\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize tokenizer and model for roberta-base\n",
        "okenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=2e-6, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "\n",
        "# 'roberta-base, BATCH_SIZE = 8, lr=2e-6, EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7MvLEvrHS5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85479af3-197e-438d-baff-9031dda82d57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/3 Loss: 0.5911389589309692\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/3 Loss: 0.42604875564575195\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/3 Loss: 0.45530638098716736\n",
            "Accuracy: 0.7643\n",
            "Total time taken: 00:20:48 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "import time  # Import the time module\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize tokenizer and model for roberta-base\n",
        "okenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 16\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=2e-6, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "\n",
        "# 'roberta-base, BATCH_SIZE = 16, lr=2e-6, EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH-XX458Ha16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea1612d-72f0-45d5-818d-114e6018615a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/5 Loss: 0.5925526022911072\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/5 Loss: 0.5701599717140198\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/5 Loss: 0.6218447089195251\n",
            "Number of trainable parameters: 201\n",
            "Epoch 4/5 Loss: 0.37999773025512695\n",
            "Number of trainable parameters: 201\n",
            "Epoch 5/5 Loss: 0.2567494213581085\n",
            "Accuracy: 0.7792\n",
            "Total time taken: 00:33:13 Using the A100 GPU\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and download the data\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "import time  # Import the time module\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Initialize tokenizer and model for roberta-base\n",
        "okenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 16\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 5\n",
        "optimizer = AdamW(model.parameters(), lr=2e-6, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "\n",
        "# 'roberta-base, BATCH_SIZE = 16, lr=2e-6, EPOCHS = 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ExKG0aa-LRpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Performance\n",
        "# Import libraries and download the data\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from transformers import pipeline\n",
        "import time  # Import the time module\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, scheduler, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Listing trainable parameters\n",
        "        trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "        print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs} Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "def load_imdb_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((1 if label == 'pos' else 0, text))\n",
        "    return pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "\n",
        "# Data Preparation - Tokenizing and padding\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "train_data = load_imdb_data('aclImdb/train')\n",
        "test_data = load_imdb_data('aclImdb/test')\n",
        "\n",
        "# Tokenizer and pre-trained BERT model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = IMDBDataset(train_data, tokenizer)\n",
        "test_dataset = IMDBDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * EPOCHS  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model\n",
        "train_model(model, train_loader, optimizer, scheduler, EPOCHS)\n",
        "\n",
        "\n",
        "# Evaluating the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the total time taken\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Convert total time into hours, minutes, seconds\n",
        "hours = int(total_time // 3600)  # 1 hour = 3600 seconds\n",
        "minutes = int((total_time % 3600) // 60)  # Get remaining minutes after hours\n",
        "seconds = int(total_time % 60)  # Get remaining seconds after minutes\n",
        "\n",
        "# Print the total time in hour:minute:second format\n",
        "print(f\"Total time taken: {hours:02}:{minutes:02}:{seconds:02} Using the A100 GPU\")\n",
        "\n",
        "# bert-based-uncased, lr=1e-5, BATCH_SIZE = 8, EPOCHS = 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUaBkNYCLTXD",
        "outputId": "3c16f499-50fb-4036-c2d7-acbc2d0db8ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 201\n",
            "Epoch 1/3 Loss: 0.12851452827453613\n",
            "Number of trainable parameters: 201\n",
            "Epoch 2/3 Loss: 0.10446888208389282\n",
            "Number of trainable parameters: 201\n",
            "Epoch 3/3 Loss: 0.038200438022613525\n",
            "Accuracy: 0.9218\n",
            "Total time taken: 00:22:07 Using the A100 GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import os\n",
        "import tarfile\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load tokenizer and models\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "sentiment_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).to(device)\n",
        "qa_model = BertForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\").to(device)\n",
        "\n",
        "# Prepare data: extract 5 random reviews and labels\n",
        "def load_reviews(path, label):\n",
        "    reviews = []\n",
        "    for filename in os.listdir(path):\n",
        "        with open(os.path.join(path, filename), \"r\", encoding=\"utf-8\") as f:\n",
        "            reviews.append((f.read(), label))\n",
        "    return reviews\n",
        "\n",
        "def ask_bert_review(text, question):\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        question,\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=512,  # Limit input length\n",
        "        truncation=True  # Truncate if longer than 512\n",
        "    ).to(device)\n",
        "\n",
        "    # Forward pass through QA model\n",
        "    answer_start_scores, answer_end_scores = qa_model(**inputs, return_dict=False)\n",
        "    answer_start = torch.argmax(answer_start_scores)\n",
        "    answer_end = torch.argmax(answer_end_scores) + 1\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
        "    return answer\n",
        "\n",
        "\n",
        "# Load positive and negative reviews\n",
        "positive_reviews = load_reviews(\"aclImdb/test/pos\", label=1)\n",
        "negative_reviews = load_reviews(\"aclImdb/test/neg\", label=0)\n",
        "\n",
        "\n",
        "# Combine and sample reviews\n",
        "all_reviews = positive_reviews + negative_reviews\n",
        "random.shuffle(all_reviews)\n",
        "sample_reviews = random.sample(all_reviews, 5)\n",
        "\n",
        "# Analyze reviews\n",
        "results = []\n",
        "\n",
        "for review, label in sample_reviews:\n",
        "    # Sentiment classification using pretrained bert - not fine tuned\n",
        "    inputs = tokenizer(review, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
        "    sentiment_output = sentiment_model(**inputs)\n",
        "    sentiment = torch.argmax(sentiment_output.logits, dim=1).item()\n",
        "    sentiment_label = \"positive\" if sentiment == 1 else \"negative\"\n",
        "    actual_label = \"positive\" if label == 1 else \"negative\"\n",
        "\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        \"review\": review,\n",
        "        \"predicted_sentiment\": sentiment_label,\n",
        "        \"actual_sentiment\": actual_label,\n",
        "        \"reason\": ask_bert_review(review, f\"Why is this review {sentiment_label}?\")\n",
        "    })\n",
        "\n",
        "# Print results\n",
        "for i, result in enumerate(results):\n",
        "    print(f\"Review {i + 1}:\")\n",
        "    print(f\"Text: {result['review'][:300]}...\")  # Truncate for display\n",
        "    print(f\"Predicted Sentiment: {result['predicted_sentiment']}\")\n",
        "    print(f\"Actual Sentiment: {result['actual_sentiment']}\")\n",
        "    print(f\"Reason: {result['reason']}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO0D1ns4LtqN",
        "outputId": "601ec3d7-b25b-43bd-bde5-47b0bb219b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review 1:\n",
            "Text: I hate to comment on something I didn't finish, but if I spare one person what I sat through for almost an hour before turning it off in disgust, it will be worth it. <br /><br />I decided to watch this with an open mind, knowing it was on the bottom 100.<br /><br />Bad idea. I usually love crude hu...\n",
            "Predicted Sentiment: negative\n",
            "Actual Sentiment: negative\n",
            "Reason: it was on the bottom 100\n",
            "\n",
            "\n",
            "Review 2:\n",
            "Text: I saw the premier of this movie during the 2005 Phoenix Film Festival and was very impressed with the skill Director, Jeff Hare, exhibited in bringing this timely topic to the screen. The cast of characters meshed perfectly and allowed us to examine the issue of a senior wishing to die on \"his own t...\n",
            "Predicted Sentiment: negative\n",
            "Actual Sentiment: positive\n",
            "Reason: if you are not afraid to shed a few tears or laugh at the quips of a family struggling with this issue\n",
            "\n",
            "\n",
            "Review 3:\n",
            "Text: I saw this film at the Sundance Film Festival and I too was surprised that it didn't generate more notice because it was not only powerful and beautifully crafted but very original. The audience was totally engaged and the greatest part of seeing a film like this at a festival is the opportunity to ...\n",
            "Predicted Sentiment: positive\n",
            "Actual Sentiment: positive\n",
            "Reason: the film is thought provoking and hilarious at the same time .\n",
            "\n",
            "\n",
            "Review 4:\n",
            "Text: The casting (and direction) in Undercurrent is more insipid than inspired in this noir clunker that fails from the outset to get off the ground. Robert Taylor's wooden style poses a roadblock almost immediately for the highly affected Kate Hepburn and it's bad chemistry from the outset.<br /><br />N...\n",
            "Predicted Sentiment: positive\n",
            "Actual Sentiment: negative\n",
            "Reason: [CLS]\n",
            "\n",
            "\n",
            "Review 5:\n",
            "Text: After putting a mummy in a local museum goes through the cat-scan, a metal object in it's brain reacts adversely to the procedure, thus freeing the spirit,or phantom if you will, of the mummy, Belphegor. Due to convenient circumstances, Lisa, who lives close to the museum finds herself possessed by ...\n",
            "Predicted Sentiment: negative\n",
            "Actual Sentiment: negative\n",
            "Reason: it can ' t help but pale in comparison to the others despite the nice locals and scenery\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import os\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForQuestionAnswering\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load tokenizer and models\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "sentiment_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).to(device)\n",
        "qa_model = BertForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\").to(device)\n",
        "\n",
        "# Prepare data: extract reviews and labels\n",
        "def load_reviews(path, label):\n",
        "    reviews = []\n",
        "    for filename in os.listdir(path):\n",
        "        with open(os.path.join(path, filename), \"r\", encoding=\"utf-8\") as f:\n",
        "            reviews.append((f.read(), label))\n",
        "    return reviews\n",
        "\n",
        "# QA function for entity-specific questions\n",
        "def ask_bert_review(text, question):\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        question,\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=512,  # Limit input length\n",
        "        truncation=True  # Truncate if longer than 512\n",
        "    ).to(device)\n",
        "\n",
        "    # Forward pass through QA model\n",
        "    answer_start_scores, answer_end_scores = qa_model(**inputs, return_dict=False)\n",
        "    answer_start = torch.argmax(answer_start_scores)\n",
        "    answer_end = torch.argmax(answer_end_scores) + 1\n",
        "    answer = tokenizer.convert_tokens_to_string(\n",
        "        tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
        "    )\n",
        "    return answer\n",
        "\n",
        "# Load positive and negative reviews\n",
        "positive_reviews = load_reviews(\"aclImdb/test/pos\", label=1)\n",
        "negative_reviews = load_reviews(\"aclImdb/test/neg\", label=0)\n",
        "\n",
        "# Combine and sample reviews\n",
        "all_reviews = positive_reviews + negative_reviews\n",
        "random.shuffle(all_reviews)\n",
        "sample_reviews = random.sample(all_reviews, 5)\n",
        "\n",
        "# Define entity-specific questions\n",
        "entity_questions = {\n",
        "    \"acting\": \"What does the review say about the acting?\",\n",
        "    \"plot\": \"Why is the plot praised or criticized?\",\n",
        "    \"direction\": \"What does the review say about the direction?\"\n",
        "}\n",
        "\n",
        "# Analyze reviews\n",
        "results = []\n",
        "\n",
        "for review, label in sample_reviews:\n",
        "    # Sentiment classification\n",
        "    inputs = tokenizer(review, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
        "    sentiment_output = sentiment_model(**inputs)\n",
        "    sentiment = torch.argmax(sentiment_output.logits, dim=1).item()\n",
        "    sentiment_label = \"positive\" if sentiment == 1 else \"negative\"\n",
        "    actual_label = \"positive\" if label == 1 else \"negative\"\n",
        "\n",
        "    # Entity-specific reasoning\n",
        "    explanations = {}\n",
        "    for aspect, question in entity_questions.items():\n",
        "        explanations[aspect] = ask_bert_review(review, question)\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        \"review\": review,\n",
        "        \"predicted_sentiment\": sentiment_label,\n",
        "        \"actual_sentiment\": actual_label,\n",
        "        \"explanations\": explanations\n",
        "    })\n",
        "\n",
        "# Print results\n",
        "for i, result in enumerate(results):\n",
        "    print(f\"Review {i + 1}:\")\n",
        "    print(f\"Text: {result['review'][:300]}...\")  # Truncate for display\n",
        "    print(f\"Predicted Sentiment: {result['predicted_sentiment']}\")\n",
        "    print(f\"Actual Sentiment: {result['actual_sentiment']}\")\n",
        "    for aspect, explanation in result[\"explanations\"].items():\n",
        "        print(f\"Reason for {aspect}: {explanation}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWEdJ01o0Bo0",
        "outputId": "e55adb7f-b7e8-45e5-8f71-f583575d9ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review 1:\n",
            "Text: Here is a movie of adventure, determination, heroism, & bravery. Plus, it's set back in the late 1800s which makes it even more interesting. It's a wonderful, adventurous storyline, and Alyssa Milano is wonderful at playing the wholesome, confident, no-nonsense Fizzy...a great role-model. This is on...\n",
            "Predicted Sentiment: positive\n",
            "Actual Sentiment: positive\n",
            "Reason for acting: alyssa milano is wonderful\n",
            "Reason for plot: excellent\n",
            "Reason for direction: wonderfully\n",
            "\n",
            "\n",
            "Review 2:\n",
            "Text: I remember being so excited on Saturday nights when I was a kid, waiting for Dr. Who. I thought it was the best show ever made. Then, I grew up, Dr. Who went off the air, and no one I knew had ever heard of it. Then I found out there was going to be a new series. I was a little nervous about it. Was...\n",
            "Predicted Sentiment: positive\n",
            "Actual Sentiment: positive\n",
            "Reason for acting: a little behind the rest of you\n",
            "Reason for plot: i ' m a little behind the rest of you\n",
            "Reason for direction: a little behind the rest of you\n",
            "\n",
            "\n",
            "Review 3:\n",
            "Text: People call a 976 \"party line\" to talk dirty to strangers, and perhaps meet up for a sexual liason. A deranged, somewhat incestuous sister and occasional transvestite brother use the line to find people to kill, usually married men, but they don't discriminate! A pair of sixteen year old girls also ...\n",
            "Predicted Sentiment: positive\n",
            "Actual Sentiment: negative\n",
            "Reason for acting: nothing too special here\n",
            "Reason for plot: \n",
            "Reason for direction: nothing too special here .\n",
            "\n",
            "\n",
            "Review 4:\n",
            "Text: It's funny... one day before i have seen this movie i had been watching a documentary about Leni Riefenstahl, so comparison kind of came automatically... of course there isn't any :)<br /><br /> This movie is weak in every aspect... acting is not convincing (especially the one who plays Simona...) a...\n",
            "Predicted Sentiment: positive\n",
            "Actual Sentiment: negative\n",
            "Reason for acting: not convincing\n",
            "Reason for plot: the story doesn ' t flow\n",
            "Reason for direction: this movie is weak in every aspect . . . acting is not convincing ( especially the one who plays simona . . . ) and unnatural . . . , editing in confused and always leaves a taste of unfinished shot , music doesn ' t fit , the story doesn ' t flow , it gets boring and the movie comes out much longer as it is\n",
            "\n",
            "\n",
            "Review 5:\n",
            "Text: Any movie should have an idea; Simple or more complex, it needs one... The problem with Fragata,..it's once more, that when he decides to make a movie, he so anxious to do \"whatsoever\" that he forgets this main detail, and as result we have the characters doing whatever without any justification, be...\n",
            "Predicted Sentiment: positive\n",
            "Actual Sentiment: negative\n",
            "Reason for acting: [CLS]\n",
            "Reason for plot: \n",
            "Reason for direction: [CLS] what does the review say about the direction ? [SEP]\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "022eeb410eb74e0ebdf3cb814e993978": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0372eb2262d84d48932902dc96117130": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03fa436c8ad4470e8eddd3474719d900": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_138f5b6d895f4cc3ab880a2ea107d8f5",
            "placeholder": "​",
            "style": "IPY_MODEL_4507ca816cd042f58af5596f4bbdb351",
            "value": "config.json: 100%"
          }
        },
        "0497a6ba5d5348a98e957731986d0a4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04ac3db545a74fd0ac0e7c3ad2d03e23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05e93cc40acb4b409d3427d424d67734": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06751ea2f8104a2598d05d75cd115a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0497a6ba5d5348a98e957731986d0a4c",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71b9ea5ba4f048118d6e7025d8334216",
            "value": 25
          }
        },
        "0b50855490f24e5993613bac79632882": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e64d4a042b564afa86f12dd24a1d20ad",
              "IPY_MODEL_1f4655233f364c02bd10dadfe16606bc",
              "IPY_MODEL_ffe5682a20c84ea9bc18ce60f8758d2b"
            ],
            "layout": "IPY_MODEL_ec150a39e814419e81b37df7c24b0939"
          }
        },
        "0c9f4274ddea481c9c1d0e80e246be6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cd6c1834ae7443a968534044d028b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f3b2a978efb42008769bb7a132a32ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a6da36b5dac463c9426ae79bfc828c6",
              "IPY_MODEL_d38655ab990748c7a5b7859347c2bddc",
              "IPY_MODEL_229d04a4abca420db5fb2ad79b0835e4"
            ],
            "layout": "IPY_MODEL_022eeb410eb74e0ebdf3cb814e993978"
          }
        },
        "0f523682c1674262a72446aa140169ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90042747e7ee4f84bd68a22c03daebb0",
              "IPY_MODEL_434b9f12652e40fd832ac6ef0e69999f",
              "IPY_MODEL_9b4de354f1b149c4bb75aa3e5b84e6f3"
            ],
            "layout": "IPY_MODEL_d787177972b5461d961545b729c1f573"
          }
        },
        "102817fa28d74602a37dbd2868a18677": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10a1bc9dccee4488b607555bb4c0d29b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122c29612d2b4fc5844f1b394a62bb8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "135bd32ea0b74cba83d78f847375bedb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "138f5b6d895f4cc3ab880a2ea107d8f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14a991f6073440e28955fc183e5d3ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d964bda6c3f4b38ad31229adb201422",
            "placeholder": "​",
            "style": "IPY_MODEL_bfa54e3f85eb43bdb703bbb7dd051cdc",
            "value": " 232k/232k [00:00&lt;00:00, 13.4MB/s]"
          }
        },
        "1694fbe70e424e1e9898299bcc0a844e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "177c5ae36cd04a27b227669d3189b7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18d9005782ea4ce680d732d53b9d0a16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "195657076576462699a9822103ab2923": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19932a39f48a4829b0945c0e2ad5294e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b5a7669a2da4d369e592d00e9540bb1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c17d76c7ee74866a7de6aa9f2249943": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dc9f59abca04daf9a7ca81bf9f890e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ead1fed8002451d991ffc73da4b827d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ebc3387b20e467cae158205e9d90074": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9af9c4bca7124010b42413ac70a3c0da",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_594cea9f10c943b4ade89940645686f2",
            "value": 456318
          }
        },
        "1f4655233f364c02bd10dadfe16606bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ebf091061bf437099b0c5115f850036",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_548837eb29d9493cbc8ccfc519ddbdab",
            "value": 267954768
          }
        },
        "1feb4598a0804213b0d1694bf136721f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21c6e4408c5b4558ab995753b02cfc04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "229d04a4abca420db5fb2ad79b0835e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a96da3ae855045fcb5ff7c7bfe97a6da",
            "placeholder": "​",
            "style": "IPY_MODEL_4f25bb0cc2b941bc9471e2a9be780fa2",
            "value": " 466k/466k [00:00&lt;00:00, 2.17MB/s]"
          }
        },
        "248e2e625f2d4850a4fc6f1eea72c807": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26e6413e1faf438692f11281640cfbd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "276e2891f8c4421587d458b839632240": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82c0c3ebc7894f4b8e9a1dae64c81e35",
            "placeholder": "​",
            "style": "IPY_MODEL_85ee92884b2645ea977ce023636975c8",
            "value": " 466k/466k [00:00&lt;00:00, 1.11MB/s]"
          }
        },
        "283a5148712b456eb59342a4907dec5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2870f14d38174edd9484fb4f6e7c80f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2928393860d749158806f18ad51edcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_603b6aba7350444788f6ac99afbf3e55",
            "placeholder": "​",
            "style": "IPY_MODEL_424195d8112246abb63def8952af26d4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2b58f91db9314ce390a564cba355b3ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b7e461650bb449d9a1001390f8f07a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d8662277df04b8ca67fbadcd6c74756": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2db1dc1ccfa5430f9c5ecf902cf988f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "302f83452c6243fdba3172e1d9cb37bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31408df57ce445d6bb580d6853c004db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe6bed3e941442f69dddbdb3d113a17b",
              "IPY_MODEL_5535ad1c96b4477486af5916c7baa04f",
              "IPY_MODEL_276e2891f8c4421587d458b839632240"
            ],
            "layout": "IPY_MODEL_21c6e4408c5b4558ab995753b02cfc04"
          }
        },
        "332e49692539416fb2a941f8bb122450": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "341db97d2fa245789d0f648aba7df34c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35fa984d493e41208bbad1e9990b8c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_302f83452c6243fdba3172e1d9cb37bb",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdd0877738dc43239a1a8e324922ddce",
            "value": 48
          }
        },
        "368333b4358643fda608795972f81c11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "369aaa670a624d97bf9c37e7999ab03e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37086f365d154bba8e598837b3357667": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "372af8035532404492216bc07623d9a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37bb3dac665d4e0fa00fad794e1e5d57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3855186ba12540a48adaeff8709813bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10a1bc9dccee4488b607555bb4c0d29b",
            "placeholder": "​",
            "style": "IPY_MODEL_455ff4ba688c45bcbec5aec28721e8b8",
            "value": "vocab.json: 100%"
          }
        },
        "39bb9782d55f45aebd4dee7c39dad393": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39c07da9f37c4a5fbd5ba842280d81b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a6da36b5dac463c9426ae79bfc828c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1a0c928430b4ed68af37ff567a9e7b4",
            "placeholder": "​",
            "style": "IPY_MODEL_102817fa28d74602a37dbd2868a18677",
            "value": "tokenizer.json: 100%"
          }
        },
        "3dc6941f051a48fb9aea6ee1eac0f1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b5a7669a2da4d369e592d00e9540bb1",
            "placeholder": "​",
            "style": "IPY_MODEL_dee9ddcbdd1f446abb8bb196efe5f7fc",
            "value": " 570/570 [00:00&lt;00:00, 52.7kB/s]"
          }
        },
        "3e6dd9db67834c90b2a1b8c98702023b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ac314c185bf4bc3b933deba5756c89d",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_902dd0a09b6c48f08e635d34e64592ca",
            "value": 267954768
          }
        },
        "40656adca53240e89854d74aa9aa4ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03fa436c8ad4470e8eddd3474719d900",
              "IPY_MODEL_5fe97cbc9d7b41b3aed36ce368b62960",
              "IPY_MODEL_3dc6941f051a48fb9aea6ee1eac0f1b6"
            ],
            "layout": "IPY_MODEL_80d6394cab8b4c5792abd8295b096700"
          }
        },
        "4156ec1a70ab4459ac70fd8004e15a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3126ebacfc94b0f92ba0e683cd441ff",
              "IPY_MODEL_3e6dd9db67834c90b2a1b8c98702023b",
              "IPY_MODEL_e8ca4449e1634e09b33c111ce4e21f2b"
            ],
            "layout": "IPY_MODEL_7e533bfc87fa437ab36a3a7eede098e1"
          }
        },
        "4171b12cebaa4feb81de1a5f229d6811": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "424195d8112246abb63def8952af26d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "434b9f12652e40fd832ac6ef0e69999f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39c07da9f37c4a5fbd5ba842280d81b3",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1feb4598a0804213b0d1694bf136721f",
            "value": 231508
          }
        },
        "4507ca816cd042f58af5596f4bbdb351": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "455085ae520a4303b911398c0c84a984": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_724a3b8ea5a04808948e25b48a3d12cc",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_712ad803c6a345368c679770ea00b26b",
            "value": 231508
          }
        },
        "455ff4ba688c45bcbec5aec28721e8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49d48d157fd146d1b06a77cd536ffb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ac314c185bf4bc3b933deba5756c89d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cb27dcad8d742d6939770ad6b87592a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dcfb1e6945946e7803f6c85a09b021f",
            "placeholder": "​",
            "style": "IPY_MODEL_ea3d8cca4d754dac878ae7233fde0e47",
            "value": "vocab.txt: 100%"
          }
        },
        "4dcfb1e6945946e7803f6c85a09b021f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ddac4494b6a4920b8ae7749a96f3035": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_248e2e625f2d4850a4fc6f1eea72c807",
            "placeholder": "​",
            "style": "IPY_MODEL_e71976cf7b4446299fa647135a71053c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4f25bb0cc2b941bc9471e2a9be780fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f5c7bdb9e814cabac72cc321c59dfb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51f74a70012c42a684ba3deb8b9a5c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "548837eb29d9493cbc8ccfc519ddbdab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "549b3c03f81747838838537572f03296": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94f735bdf75f4af4b1b0cb02102c7d06",
              "IPY_MODEL_cb54f8a6e4f148f5b516b505e26cb03c",
              "IPY_MODEL_59a883804d9e4b388866e44fff30dc52"
            ],
            "layout": "IPY_MODEL_135bd32ea0b74cba83d78f847375bedb"
          }
        },
        "5535ad1c96b4477486af5916c7baa04f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dc9f59abca04daf9a7ca81bf9f890e7",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97a4e003eb494efca981a487c02383ec",
            "value": 466062
          }
        },
        "55dd229b4d8c42f784f435c74a8d1573": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde6a87bb25246a8ae9de6e70423e6f3",
            "placeholder": "​",
            "style": "IPY_MODEL_ec2ab47f5b7948548f4df152f7ce2e88",
            "value": " 232k/232k [00:00&lt;00:00, 558kB/s]"
          }
        },
        "56509619de3d479db1363222621f07b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56981526527a4ba8b1db9e7640db5754": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5881c9351d74495894f300831fd3d2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5912df4c9941493899a1fd2349561428": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab1c400f54f74f468f8444b9ee2cc7fb",
              "IPY_MODEL_1ebc3387b20e467cae158205e9d90074",
              "IPY_MODEL_9893c9670af64ca795597b513e657d77"
            ],
            "layout": "IPY_MODEL_9efac6017eb04cc9a775968ea56d298c"
          }
        },
        "5918438a52844d54acca528eed82e655": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fce48e586a354b99955e4e3db8eb0582",
            "placeholder": "​",
            "style": "IPY_MODEL_0cd6c1834ae7443a968534044d028b97",
            "value": "vocab.txt: 100%"
          }
        },
        "594cea9f10c943b4ade89940645686f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59a883804d9e4b388866e44fff30dc52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f38dd426b89542ff8574519d1545e05b",
            "placeholder": "​",
            "style": "IPY_MODEL_e0dd1d6af50644e3957b3ad6f0f9ec47",
            "value": " 483/483 [00:00&lt;00:00, 43.0kB/s]"
          }
        },
        "59ae7c8e68004f7b8b90ee003c3faadb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59d1cf1733cb44b09d8ecf798176a73f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93ca550fe8b3482aaeba280c9aeccd7c",
            "placeholder": "​",
            "style": "IPY_MODEL_1ead1fed8002451d991ffc73da4b827d",
            "value": "config.json: 100%"
          }
        },
        "5a473597c2b54f0aa0bef3b8886ad59d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b99df92219d47e1b95994c24bc8ee26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d8b5921d17d4ab9bbc6623048f91047": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dd5b8a67b3e406a9355d542c7370001": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7adcf7f5c8e0482ba6f2d7288da4b464",
            "placeholder": "​",
            "style": "IPY_MODEL_a69bd0017f8b4ee5b0a3cd02bea10af6",
            "value": "model.safetensors: 100%"
          }
        },
        "5e95dfca62104215a7aa775d75bb8827": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ea591de78d04d29933686656c2622f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fe97cbc9d7b41b3aed36ce368b62960": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_372af8035532404492216bc07623d9a5",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56981526527a4ba8b1db9e7640db5754",
            "value": 570
          }
        },
        "603b6aba7350444788f6ac99afbf3e55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6560ca377cca48b498a38744cbe70ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "662ba766179d4030870f508a47e90505": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76cf09d4f7ab4decade762aa5cb7d11c",
            "placeholder": "​",
            "style": "IPY_MODEL_f456ad032ee645588e8b418bad955625",
            "value": " 48.0/48.0 [00:00&lt;00:00, 4.07kB/s]"
          }
        },
        "67d7ee62dd864e0a9c69fdf486822176": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68399aace30e45a691a8975341d7b538": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68b2fa37bbdb4b47983ba2d526f1459c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a47970f9b5847678f1f31c440868ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d7cb082184f4b808aa8716a522d400a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ebf091061bf437099b0c5115f850036": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "712ad803c6a345368c679770ea00b26b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71b9ea5ba4f048118d6e7025d8334216": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "724a3b8ea5a04808948e25b48a3d12cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a8e47be0a44f2696d73a4807bdce93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "754c7f138dfe407cbfa5e69001341630": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "763daa0709a74d8f8cfd68d10e3d31a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76cf09d4f7ab4decade762aa5cb7d11c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7adcf7f5c8e0482ba6f2d7288da4b464": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7adf3aa1ab2e4b0b9a91f1c976b80f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cb27dcad8d742d6939770ad6b87592a",
              "IPY_MODEL_455085ae520a4303b911398c0c84a984",
              "IPY_MODEL_14a991f6073440e28955fc183e5d3ad2"
            ],
            "layout": "IPY_MODEL_86c1b6111a724c03a6d05d72a7fc4c3d"
          }
        },
        "7c37ecfeae874e3f84130ed2984346ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5dd5b8a67b3e406a9355d542c7370001",
              "IPY_MODEL_a895076f177144c4b4bf0cbdc6400a31",
              "IPY_MODEL_a952203b044f4c1ba2278b2b6a69c913"
            ],
            "layout": "IPY_MODEL_bd8b94cbfad841c1bdf9de2bc745f8a1"
          }
        },
        "7e533bfc87fa437ab36a3a7eede098e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f9668b543734a8ab3b1b84dc3372c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9642d14def744bf85a49e233188de9d",
            "placeholder": "​",
            "style": "IPY_MODEL_2b58f91db9314ce390a564cba355b3ab",
            "value": " 483/483 [00:00&lt;00:00, 40.5kB/s]"
          }
        },
        "80d6394cab8b4c5792abd8295b096700": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82c0c3ebc7894f4b8e9a1dae64c81e35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84397eb3e19547de82f2d035378180ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c86303f43e26496d9e69e3bca5a1b753",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a47970f9b5847678f1f31c440868ec2",
            "value": 440449768
          }
        },
        "85ee92884b2645ea977ce023636975c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86a7e400a2e0436e88a6f8d1755ffd72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86c1b6111a724c03a6d05d72a7fc4c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87dae17fe02040768a113f49da8df7d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d964bda6c3f4b38ad31229adb201422": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8da059125c7944b99431b1c60cae8c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f4b065b292244ce8b66b0a9e7c2b001": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59d1cf1733cb44b09d8ecf798176a73f",
              "IPY_MODEL_a2323cf43ef94d47bb027485baecaa32",
              "IPY_MODEL_fab5f6807f77487fbea80331e753fd3d"
            ],
            "layout": "IPY_MODEL_f9727fce24284fe3af0e71164e95470a"
          }
        },
        "90042747e7ee4f84bd68a22c03daebb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed9c97fa11de4637b3153d9615829426",
            "placeholder": "​",
            "style": "IPY_MODEL_195657076576462699a9822103ab2923",
            "value": "vocab.txt: 100%"
          }
        },
        "9009678d38f3419b9a5c68f2bf8407d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "902dd0a09b6c48f08e635d34e64592ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93ca550fe8b3482aaeba280c9aeccd7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9458745579664e14bd9e490282fd2e83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e62f1110044ff69120667394b98918": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccfe9d8f48d7483dbda121816b92a0e5",
            "placeholder": "​",
            "style": "IPY_MODEL_5d8b5921d17d4ab9bbc6623048f91047",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.62MB/s]"
          }
        },
        "94f735bdf75f4af4b1b0cb02102c7d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_369aaa670a624d97bf9c37e7999ab03e",
            "placeholder": "​",
            "style": "IPY_MODEL_56509619de3d479db1363222621f07b8",
            "value": "config.json: 100%"
          }
        },
        "977f8b62e34c4404814628d5732d82e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5e704ea75514f6f8df0ae1ad849a296",
            "placeholder": "​",
            "style": "IPY_MODEL_5b99df92219d47e1b95994c24bc8ee26",
            "value": "tokenizer.json: 100%"
          }
        },
        "97a4e003eb494efca981a487c02383ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "984b0a662f374d50a2a9d8541434488f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c355bcf4866244d1aafea956317145d2",
            "placeholder": "​",
            "style": "IPY_MODEL_9009678d38f3419b9a5c68f2bf8407d5",
            "value": " 466k/466k [00:00&lt;00:00, 945kB/s]"
          }
        },
        "9893c9670af64ca795597b513e657d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c9f4274ddea481c9c1d0e80e246be6d",
            "placeholder": "​",
            "style": "IPY_MODEL_4f5c7bdb9e814cabac72cc321c59dfb3",
            "value": " 456k/456k [00:00&lt;00:00, 1.07MB/s]"
          }
        },
        "9a3fe022f650482a8255191670896c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3855186ba12540a48adaeff8709813bb",
              "IPY_MODEL_f8c2cf0e4559464e9cc1691c47efdf58",
              "IPY_MODEL_cc31c93623214d328cc8dea993ae673f"
            ],
            "layout": "IPY_MODEL_c7660a3ca2b24623b11d94b0a0d830b3"
          }
        },
        "9af9c4bca7124010b42413ac70a3c0da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b4de354f1b149c4bb75aa3e5b84e6f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37bb3dac665d4e0fa00fad794e1e5d57",
            "placeholder": "​",
            "style": "IPY_MODEL_177c5ae36cd04a27b227669d3189b7e2",
            "value": " 232k/232k [00:00&lt;00:00, 557kB/s]"
          }
        },
        "9ea94019b2bc4aef8515562715fb20ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9efac6017eb04cc9a775968ea56d298c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c3f75821c245b9a2e702c0875e0622": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2323cf43ef94d47bb027485baecaa32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4d400fb128c48df88ea54f828470dbe",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef86d9222dbb434ab515853dc9047b39",
            "value": 481
          }
        },
        "a38b1fddce15453ba505a929343e9f6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4591631330e4c759f2ab171e1c2cf5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4b253d546014778bec6e1a18fb1397e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_368333b4358643fda608795972f81c11",
            "placeholder": "​",
            "style": "IPY_MODEL_341db97d2fa245789d0f648aba7df34c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a5121dd2cf514d228a932e69f00d6305": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26e6413e1faf438692f11281640cfbd5",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4dd15ad30b1480ba597ea08bf030a17",
            "value": 1355863
          }
        },
        "a561b48c27b84d9db34c7a80f555a5ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5c1c95209f64443b42192a581d84341": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2d1b4dd96d445548deaed3c14166613",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_283a5148712b456eb59342a4907dec5a",
            "value": 483
          }
        },
        "a5e704ea75514f6f8df0ae1ad849a296": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a69bd0017f8b4ee5b0a3cd02bea10af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a895076f177144c4b4bf0cbdc6400a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37086f365d154bba8e598837b3357667",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c17d76c7ee74866a7de6aa9f2249943",
            "value": 498818054
          }
        },
        "a952203b044f4c1ba2278b2b6a69c913": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af4ab7aaf9914da9a7370397d19dd2b9",
            "placeholder": "​",
            "style": "IPY_MODEL_0372eb2262d84d48932902dc96117130",
            "value": " 499M/499M [00:02&lt;00:00, 244MB/s]"
          }
        },
        "a96da3ae855045fcb5ff7c7bfe97a6da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab1c400f54f74f468f8444b9ee2cc7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb55bbb85de74b3db8d1ff85bac0effa",
            "placeholder": "​",
            "style": "IPY_MODEL_2db1dc1ccfa5430f9c5ecf902cf988f1",
            "value": "merges.txt: 100%"
          }
        },
        "af4ab7aaf9914da9a7370397d19dd2b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af7c12de491744f28ee62f84ef771135": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5918438a52844d54acca528eed82e655",
              "IPY_MODEL_c4826ba981bd4d77884008e2e9696181",
              "IPY_MODEL_55dd229b4d8c42f784f435c74a8d1573"
            ],
            "layout": "IPY_MODEL_5a473597c2b54f0aa0bef3b8886ad59d"
          }
        },
        "b2ea17d53d8b46008be70d30b946aeac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2928393860d749158806f18ad51edcf1",
              "IPY_MODEL_06751ea2f8104a2598d05d75cd115a27",
              "IPY_MODEL_e430da78a58f4f508102f5325da491e5"
            ],
            "layout": "IPY_MODEL_9458745579664e14bd9e490282fd2e83"
          }
        },
        "b3bc77d461564bd78150ec30c4decef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0f7d499e67e4b4284170d6959f46c45",
              "IPY_MODEL_b637ca72106d4518bc551a23e47d2668",
              "IPY_MODEL_984b0a662f374d50a2a9d8541434488f"
            ],
            "layout": "IPY_MODEL_59ae7c8e68004f7b8b90ee003c3faadb"
          }
        },
        "b4d400fb128c48df88ea54f828470dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e02ae1d8f346e1835737a33431238d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b637ca72106d4518bc551a23e47d2668": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec9a28cf00ce47c3854eaf51929353e8",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5881c9351d74495894f300831fd3d2c4",
            "value": 466062
          }
        },
        "b8073bd4f3464c37aca358fe65095c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9e29a225d764d6490e89441389ea7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba6a4a95dfe44c6f9f8eb02e5135c239": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd1038c79ae74e54aaae5d7121069064": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd8b94cbfad841c1bdf9de2bc745f8a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be3fd2681a9743708998a341448564d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efb8073881424745abcc80fef7f58615",
              "IPY_MODEL_84397eb3e19547de82f2d035378180ca",
              "IPY_MODEL_c1a15e4556614d1ea725c73d6ce461ef"
            ],
            "layout": "IPY_MODEL_68b2fa37bbdb4b47983ba2d526f1459c"
          }
        },
        "bfa54e3f85eb43bdb703bbb7dd051cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1a15e4556614d1ea725c73d6ce461ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd49addce36d435da3dceff433aa95f7",
            "placeholder": "​",
            "style": "IPY_MODEL_c3afd4544b1f4fecb09d99a736b003b1",
            "value": " 440M/440M [00:01&lt;00:00, 246MB/s]"
          }
        },
        "c2d1b4dd96d445548deaed3c14166613": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c355bcf4866244d1aafea956317145d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3afd4544b1f4fecb09d99a736b003b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4826ba981bd4d77884008e2e9696181": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4591631330e4c759f2ab171e1c2cf5e",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_332e49692539416fb2a941f8bb122450",
            "value": 231508
          }
        },
        "c4bd5871717a49eea739c18660c62d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c78cc67e5bc34574807d8dfeb26a1887",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd1038c79ae74e54aaae5d7121069064",
            "value": 48
          }
        },
        "c529239732f04195a8407896c3c740be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2870f14d38174edd9484fb4f6e7c80f8",
            "placeholder": "​",
            "style": "IPY_MODEL_b8073bd4f3464c37aca358fe65095c71",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c588915afe6841a6ab8a2950e5856a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6c62f01e24c448c9e06abbe3349d77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7660a3ca2b24623b11d94b0a0d830b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c78cc67e5bc34574807d8dfeb26a1887": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c86303f43e26496d9e69e3bca5a1b753": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9642d14def744bf85a49e233188de9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb54f8a6e4f148f5b516b505e26cb03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de38a0aedb054bbd89550bc092b98e82",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e415008bce1347e698758b6a1e532a61",
            "value": 483
          }
        },
        "cc31c93623214d328cc8dea993ae673f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18d9005782ea4ce680d732d53b9d0a16",
            "placeholder": "​",
            "style": "IPY_MODEL_c588915afe6841a6ab8a2950e5856a3c",
            "value": " 899k/899k [00:00&lt;00:00, 1.44MB/s]"
          }
        },
        "cc98115d561345c3a3daba79b69e3f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ddac4494b6a4920b8ae7749a96f3035",
              "IPY_MODEL_da83b2b6bf7240c9b49c14de78f073d8",
              "IPY_MODEL_d362376dd5cb48d3a144096b1d46b83e"
            ],
            "layout": "IPY_MODEL_04ac3db545a74fd0ac0e7c3ad2d03e23"
          }
        },
        "ccfe9d8f48d7483dbda121816b92a0e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde6a87bb25246a8ae9de6e70423e6f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3126ebacfc94b0f92ba0e683cd441ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a38b1fddce15453ba505a929343e9f6e",
            "placeholder": "​",
            "style": "IPY_MODEL_51f74a70012c42a684ba3deb8b9a5c22",
            "value": "model.safetensors: 100%"
          }
        },
        "d362376dd5cb48d3a144096b1d46b83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1694fbe70e424e1e9898299bcc0a844e",
            "placeholder": "​",
            "style": "IPY_MODEL_c6c62f01e24c448c9e06abbe3349d77a",
            "value": " 48.0/48.0 [00:00&lt;00:00, 4.61kB/s]"
          }
        },
        "d38655ab990748c7a5b7859347c2bddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d8662277df04b8ca67fbadcd6c74756",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d7cb082184f4b808aa8716a522d400a",
            "value": 466062
          }
        },
        "d3954bcd89bf4787981989057167bd4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5b7f1d416b843969be06e3e94a0b9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8da059125c7944b99431b1c60cae8c8e",
            "placeholder": "​",
            "style": "IPY_MODEL_b9e29a225d764d6490e89441389ea7f3",
            "value": "config.json: 100%"
          }
        },
        "d787177972b5461d961545b729c1f573": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da83b2b6bf7240c9b49c14de78f073d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a561b48c27b84d9db34c7a80f555a5ae",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba6a4a95dfe44c6f9f8eb02e5135c239",
            "value": 48
          }
        },
        "dd49addce36d435da3dceff433aa95f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de38a0aedb054bbd89550bc092b98e82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dee1440d192844aba962d7cf9ba34daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4b253d546014778bec6e1a18fb1397e",
              "IPY_MODEL_35fa984d493e41208bbad1e9990b8c88",
              "IPY_MODEL_e80c4b0f681e4ca3b28ce5d24432c2d6"
            ],
            "layout": "IPY_MODEL_74a8e47be0a44f2696d73a4807bdce93"
          }
        },
        "dee9ddcbdd1f446abb8bb196efe5f7fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0dd1d6af50644e3957b3ad6f0f9ec47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0f7d499e67e4b4284170d6959f46c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68399aace30e45a691a8975341d7b538",
            "placeholder": "​",
            "style": "IPY_MODEL_86a7e400a2e0436e88a6f8d1755ffd72",
            "value": "tokenizer.json: 100%"
          }
        },
        "e1a0c928430b4ed68af37ff567a9e7b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e415008bce1347e698758b6a1e532a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e430da78a58f4f508102f5325da491e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3954bcd89bf4787981989057167bd4c",
            "placeholder": "​",
            "style": "IPY_MODEL_49d48d157fd146d1b06a77cd536ffb7b",
            "value": " 25.0/25.0 [00:00&lt;00:00, 2.27kB/s]"
          }
        },
        "e4dd15ad30b1480ba597ea08bf030a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e64d4a042b564afa86f12dd24a1d20ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e722364c5be74d61a1b37e3966fdd888",
            "placeholder": "​",
            "style": "IPY_MODEL_19932a39f48a4829b0945c0e2ad5294e",
            "value": "model.safetensors: 100%"
          }
        },
        "e71976cf7b4446299fa647135a71053c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e722364c5be74d61a1b37e3966fdd888": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e80c4b0f681e4ca3b28ce5d24432c2d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39bb9782d55f45aebd4dee7c39dad393",
            "placeholder": "​",
            "style": "IPY_MODEL_5ea591de78d04d29933686656c2622f5",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.40kB/s]"
          }
        },
        "e8616c4662404401b720ff8500ce4f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8ca4449e1634e09b33c111ce4e21f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87dae17fe02040768a113f49da8df7d8",
            "placeholder": "​",
            "style": "IPY_MODEL_763daa0709a74d8f8cfd68d10e3d31a5",
            "value": " 268M/268M [00:01&lt;00:00, 251MB/s]"
          }
        },
        "ea3d8cca4d754dac878ae7233fde0e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb55bbb85de74b3db8d1ff85bac0effa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec150a39e814419e81b37df7c24b0939": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec2ab47f5b7948548f4df152f7ce2e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec9a28cf00ce47c3854eaf51929353e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed9c97fa11de4637b3153d9615829426": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee5ce0cfa81341129a5cec5bcfccdafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5b7f1d416b843969be06e3e94a0b9fa",
              "IPY_MODEL_a5c1c95209f64443b42192a581d84341",
              "IPY_MODEL_7f9668b543734a8ab3b1b84dc3372c86"
            ],
            "layout": "IPY_MODEL_67d7ee62dd864e0a9c69fdf486822176"
          }
        },
        "eef1581667d24e0387e1e04ab82c170c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef86d9222dbb434ab515853dc9047b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efb8073881424745abcc80fef7f58615": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6560ca377cca48b498a38744cbe70ed9",
            "placeholder": "​",
            "style": "IPY_MODEL_e8616c4662404401b720ff8500ce4f34",
            "value": "model.safetensors: 100%"
          }
        },
        "f38dd426b89542ff8574519d1545e05b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f456ad032ee645588e8b418bad955625": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8c2cf0e4559464e9cc1691c47efdf58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b7e461650bb449d9a1001390f8f07a3",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4e02ae1d8f346e1835737a33431238d",
            "value": 898823
          }
        },
        "f9727fce24284fe3af0e71164e95470a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f987458617e345df9647d99d2c71accc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c529239732f04195a8407896c3c740be",
              "IPY_MODEL_c4bd5871717a49eea739c18660c62d22",
              "IPY_MODEL_662ba766179d4030870f508a47e90505"
            ],
            "layout": "IPY_MODEL_122c29612d2b4fc5844f1b394a62bb8a"
          }
        },
        "fab5f6807f77487fbea80331e753fd3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05e93cc40acb4b409d3427d424d67734",
            "placeholder": "​",
            "style": "IPY_MODEL_9ea94019b2bc4aef8515562715fb20ec",
            "value": " 481/481 [00:00&lt;00:00, 39.2kB/s]"
          }
        },
        "fce48e586a354b99955e4e3db8eb0582": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdd0877738dc43239a1a8e324922ddce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe6bed3e941442f69dddbdb3d113a17b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eef1581667d24e0387e1e04ab82c170c",
            "placeholder": "​",
            "style": "IPY_MODEL_a1c3f75821c245b9a2e702c0875e0622",
            "value": "tokenizer.json: 100%"
          }
        },
        "ff6dfcbb37aa4d689a96692758f28e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_977f8b62e34c4404814628d5732d82e3",
              "IPY_MODEL_a5121dd2cf514d228a932e69f00d6305",
              "IPY_MODEL_94e62f1110044ff69120667394b98918"
            ],
            "layout": "IPY_MODEL_4171b12cebaa4feb81de1a5f229d6811"
          }
        },
        "ffe5682a20c84ea9bc18ce60f8758d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_754c7f138dfe407cbfa5e69001341630",
            "placeholder": "​",
            "style": "IPY_MODEL_5e95dfca62104215a7aa775d75bb8827",
            "value": " 268M/268M [00:01&lt;00:00, 247MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}